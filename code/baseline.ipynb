{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "#from progressbar import *  \n",
    "from tqdm._tqdm import trange\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "age_train = pd.read_csv(\"age_train.csv\", names=['uid','age_group'])\n",
    "age_test = pd.read_csv(\"age_test.csv\", names=['uid'])\n",
    "user_basic_info = pd.read_csv(\"user_basic_info.csv\", names=['uid','gender','city','prodName','ramCapacity','ramLeftRation','romCapacity','romLeftRation','color','fontSize','ct','carrier','os'])\n",
    "user_behavior_info = pd.read_csv(\"user_behavior_info.csv\", names=['uid','bootTimes','AFuncTimes','BFuncTimes','CFuncTimes','DFuncTimes','EFuncTimes','FFuncTimes','FFuncSum'])\n",
    "user_app_actived = pd.read_csv(\"user_app_actived.csv\", names=['uid','appId'])\n",
    "\n",
    "app_info = pd.read_csv(\"app_info.csv\", names=['appId', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理数据量较大的user_app_usage.csv，结合app_info.csv简单统计得到appuseProcessed.csv作为特征\n",
    "def f(x):\n",
    "    s = x.value_counts()\n",
    "    return np.nan if len(s) == 0 else s.index[0]\n",
    "def processUserAppUsage():\n",
    "    resTable = pd.DataFrame()\n",
    "    reader = pd.read_csv(\"user_app_usage.csv\", names=['uid','appId','duration','times','use_date'], iterator=True)\n",
    "    last_df = pd.DataFrame()\n",
    "    \n",
    "    app_info = pd.read_csv(\"app_info.csv\", names=['appId','category'])\n",
    "    # 统计出共有多少种类别的app\n",
    "    cats = list(set(app_info['category']))\n",
    "    category2id = dict(zip(sorted(cats), range(0,len(cats))))\n",
    "    id2category = dict(zip(range(0,len(cats)), sorted(cats)))\n",
    "    app_info['category'] = app_info['category'].apply(lambda x: category2id[x])\n",
    "    i = 1\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            print(\"index: {}\".format(i))\n",
    "            i+=1\n",
    "            df = reader.get_chunk(1000000)\n",
    "            df = pd.concat([last_df, df])\n",
    "            idx = df.shape[0]-1\n",
    "            last_user = df.iat[idx,0]\n",
    "            while(df.iat[idx,0]==last_user):\n",
    "                idx-=1\n",
    "            last_df = df[idx+1:]\n",
    "            df = df[:idx+1]\n",
    "\n",
    "            now_df = pd.DataFrame()\n",
    "            now_df['uid'] = df['uid'].unique()\n",
    "            now_df = now_df.merge(df.groupby('uid')['appId'].count().to_frame(), how='left', on='uid')\n",
    "            now_df = now_df.merge(df.groupby('uid')['appId','use_date'].agg(['nunique']), how='left', on='uid')\n",
    "            now_df = now_df.merge(df.groupby('uid')['duration','times'].agg(['mean','max','std']), how='left', on='uid')    \n",
    "\n",
    "            now_df.columns = ['uid','usage_cnt','usage_appid_cnt','usage_date_cnt','duration_mean','duration_max','duration_std','times_mean','times_max','times_std']\n",
    "\n",
    "\n",
    "            df = df.merge(app_info, how='left', on='appId')\n",
    "            now_df = now_df.merge(df.groupby('uid')['category'].nunique().to_frame(), how='left', on='uid')\n",
    "            #print(df.groupby(['uid'])['category'].value_counts().index[0])\n",
    "            now_df['usage_most_used_category'] = df.groupby(['uid'])['category'].transform(f)\n",
    "            resTable = pd.concat([resTable, now_df])\n",
    "        except StopIteration:\n",
    "            break\n",
    "    \n",
    "    resTable.to_csv(\"appuseProcessed.csv\",index=0)\n",
    "    \n",
    "    print(\"Iterator is stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processUserAppUsage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将user_basic_info.csv 和 user_behavior_info.csv中的字符值编码成可以训练的数值类型，合并\n",
    "class2id = {}\n",
    "id2class = {}\n",
    "def mergeBasicTables(baseTable):\n",
    "    resTable = baseTable.merge(user_basic_info, how='left', on='uid', suffixes=('_base0', '_ubaf'))\n",
    "    resTable = resTable.merge(user_behavior_info, how='left', on='uid', suffixes=('_base1', '_ubef'))\n",
    "    cat_columns = ['city','prodName','color','carrier','os','ct']\n",
    "    for c in cat_columns:\n",
    "        resTable[c] = resTable[c].apply(lambda x: x if type(x)==str else str(x))\n",
    "        sort_temp = sorted(list(set(resTable[c])))  \n",
    "        class2id[c+'2id'] = dict(zip(sort_temp, range(1, len(sort_temp)+1)))\n",
    "        id2class['id2'+c] = dict(zip(range(1,len(sort_temp)+1), sort_temp))\n",
    "        resTable[c] = resTable[c].apply(lambda x: class2id[c+'2id'][x])\n",
    "        \n",
    "    return resTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理app使用相关数据\n",
    "#对user_app_actived.csv简单统计\n",
    "# 将之前训练的appuseProcess.csv进行合并，只统计激活的app的个数\n",
    "\n",
    "# 进阶——对user_app_actived.csv高级统计——统计用户安装的每种APP的数目\n",
    "\n",
    "def mergeAppData(baseTable):\n",
    "    resTable = baseTable.merge(user_app_actived, how='left', on='uid')\n",
    "    resTable['appId'] = resTable['appId'].apply(lambda x: len(list(x.split('#'))))\n",
    "    appusedTable = pd.read_csv(\"appuseProcessed.csv\")\n",
    "    resTable = resTable.merge(appusedTable, how='left', on='uid')\n",
    "    resTable[['category', 'usage_most_used_category']] = resTable[['category', 'usage_most_used_category']].fillna(41)\n",
    "    resTable = resTable.fillna(0)\n",
    "    #print(resTable[:5])\n",
    "    return resTable\n",
    "\n",
    "import csv\n",
    "\n",
    "def SaveFile2csv(path,contents):\n",
    "    f=open(path,'a+')\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(contents)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  cats = list(set(app_info['category']))\n",
    "#  category2id = dict(zip(sorted(cats), range(0,len(cats))))\n",
    "#  id2category = dict(zip(range(0,len(cats)), sorted(cats)))\n",
    "#  app_info['category'] = app_info['category'].apply(lambda x: category2id[x])\n",
    "\n",
    "\n",
    "# 统计出共有多少种类别的app\n",
    "#app_info = pd.read_csv(\"app_info.csv\", names=['appId','category'])\n",
    "#cats = list(set(app_info['category']))\n",
    "#category2id = dict(zip(sorted(cats), range(0,len(cats))))\n",
    "#id2category = dict(zip(range(0,len(cats)), sorted(cats)))\n",
    "#app_info['category'] = app_info['category'].apply(lambda x: category2id[x])\n",
    "\n",
    "\n",
    "\n",
    "#print(app_info)\n",
    "#print(len(set(app_info['category'])))\n",
    "#print(id2category)\n",
    "#print(category2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mergeBasicTables(age_train)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appuseProcessed_df = pd.read_csv(\"appuseProcessed.csv\")\n",
    "appuseProcessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resTable = appuseProcessed_df\n",
    "resTable[['category', 'usage_most_used_category']] = resTable[['category', 'usage_most_used_category']].fillna(41)\n",
    "resTable = resTable.fillna(0)\n",
    "resTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processUserAppUsageUpgrade(table, name):\n",
    "    #if name == 'trainSet':\n",
    "    #    resTable = pd.read_csv(\"add_40_actived_classes_features.csv\")\n",
    "    #else :\n",
    "    #    resTable = table\n",
    "    reader = pd.read_csv(\"user_app_usage.csv\", names=['uid','appId','duration','times','use_date'], iterator=True)\n",
    "    last_df = pd.DataFrame()\n",
    "    i = 1\n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            print(\"index: {}\".format(i))\n",
    "            i+=1\n",
    "            df = reader.get_chunk(1000000)\n",
    "            # 最后的user去掉\n",
    "            df = pd.concat([last_df, df])\n",
    "            idx = df.shape[0]-1\n",
    "            last_user = df.iat[idx,0]\n",
    "            while(df.iat[idx,0]==last_user):\n",
    "                idx-=1\n",
    "            last_df = df[idx+1:]\n",
    "            df = df[:idx+1]\n",
    "            \n",
    "            # 添加列，计算每类app的使用时长\n",
    "            for ii in range(40):\n",
    "                df['duration' + str(ii)] = 0\n",
    "            \n",
    "            \n",
    "            # 注意给的数据中，用户激活的app中有一些是不在app_info 中的，可以先忽略或者单独归为一类\n",
    "            app_info = pd.read_csv(\"app_info.csv\", names=['appId','category'])\n",
    "            # 统计出共有多少种类别的app\n",
    "            cats = list(set(app_info['category']))\n",
    "            category2id = dict(zip(sorted(cats), range(0,len(cats))))\n",
    "            id2category = dict(zip(range(0,len(cats)), sorted(cats)))\n",
    "            app_info['category'] = app_info['category'].apply(lambda x: category2id[x])\n",
    "\n",
    "            # app_info转dict\n",
    "            app_info_dict = app_info.set_index('appId').T.to_dict('list')\n",
    "            \n",
    "            df_dict = df.to_dict(orient= 'dict')\n",
    "            \n",
    "            pbar = tqdm(total=len(df_dict['uid']))  \n",
    "            first_user = 'abc'\n",
    "            first_user_idx = 0\n",
    "            \n",
    "            for index in df_dict['uid']:\n",
    "                pbar.update(1)\n",
    "                \n",
    "                appId = df_dict['appId'][index]\n",
    "                curUID = df_dict['uid'][index]\n",
    "                curDuration = df_dict['duration'][index]\n",
    "                if curUID != first_user :\n",
    "                    first_user = curUID\n",
    "                    first_user_idx = index\n",
    "                    \n",
    "                \n",
    "                if appId in app_info_dict.keys():\n",
    "                    df_dict[\"duration\" + str(app_info_dict[appId][0])][first_user_idx] += curDuration\n",
    "                        #if index < 10:\n",
    "                         #   print(df.head())\n",
    "                          #  print(df.shape)\n",
    "                           # print(\"first_user_idx:\" + str(first_user_idx))\n",
    "            pbar.close()\n",
    "            \n",
    "            #字典完再转回dataframe\n",
    "            df = pd.DataFrame.from_dict(df_dict)\n",
    "            #去除uid的重复项\n",
    "            df = df.drop_duplicates(['uid'])\n",
    "            df = df.drop(['appId', 'duration', 'times', 'use_date'], axis = 1)\n",
    "            \n",
    "            if i==2 :\n",
    "                df.to_csv('process_user_app_usage.csv', mode='a', header=True)\n",
    "            else:\n",
    "                df.to_csv('process_user_app_usage.csv', mode='a', header=False)\n",
    "\n",
    "            #print(df.head())\n",
    "            \n",
    "            # resTable = resTable.merge(df, how='left', on='uid')\n",
    "            del df\n",
    "            del df_dict\n",
    "            gc.collect()\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    #resTable.to_csv(\"2nd_featureEngineering_\"+ name + \".csv\",index=0)\n",
    "    \n",
    "    print(\"Iterator is stopped\")\n",
    "    #return resTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeAppDataUpgrade(baseTable):\n",
    "    \n",
    "    resTable = baseTable.merge(user_app_actived, how='left', on='uid')\n",
    "    resTable['appId'] = resTable['appId'].apply(lambda x: len(list(x.split('#'))))\n",
    "\n",
    "    appusedTable = pd.read_csv(\"appuseProcessed.csv\")\n",
    "    resTable = resTable.merge(appusedTable, how='left', on='uid')\n",
    "    resTable[['category', 'usage_most_used_category']] = resTable[['category', 'usage_most_used_category']].fillna(41)\n",
    "    resTable = resTable.fillna(0)\n",
    "\n",
    "\n",
    "    now_df = pd.DataFrame()\n",
    "    now_df['uid'] = resTable['uid']\n",
    "    for i in range(40):\n",
    "        now_df[str(i)] = 0\n",
    "\n",
    "    now_df = pd.merge(resTable, now_df, how='left', on='uid')\n",
    "\n",
    "    now_df = now_df.fillna(0)\n",
    "\n",
    "    #    now_df = now_df.merge(df.groupby('uid')['category'].nunique().to_frame(), how='left', on='uid')\n",
    "        #print(df.groupby(['uid'])['category'].value_counts().index[0])\n",
    "\n",
    "        # 开始计算每类APP的个数\n",
    "    #resTable = pd.merge(resTable, now_df, how='left', on='uid')\n",
    "\n",
    "\n",
    "\n",
    "    # 注意给的数据中，用户激活的app中有一些是不在app_info 中的，可以先忽略或者单独归为一类\n",
    "    app_info = pd.read_csv(\"app_info.csv\", names=['appId','category'])\n",
    "    # 统计出共有多少种类别的app\n",
    "    cats = list(set(app_info['category']))\n",
    "    category2id = dict(zip(sorted(cats), range(0,len(cats))))\n",
    "    id2category = dict(zip(range(0,len(cats)), sorted(cats)))\n",
    "    app_info['category'] = app_info['category'].apply(lambda x: category2id[x])\n",
    "    \n",
    "    # app_info转dict\n",
    "    app_info_dict = app_info.set_index('appId').T.to_dict('list')\n",
    "\n",
    "    now_df = pd.merge(now_df, user_app_actived, how='left', on='uid')\n",
    "    \n",
    "    try:\n",
    "        with tqdm(range(0, len(now_df))) as t:\n",
    "            for index in t:\n",
    "                appIdList = now_df.at[index, 'appId_y'].split('#')\n",
    "                for appId in appIdList:\n",
    "                    if appId in app_info_dict.keys():\n",
    "                        now_df.at[index, str(app_info_dict[appId][0])] += 1\n",
    "    except KeyboardInterrupt:\n",
    "        t.close()\n",
    "        raise\n",
    "    t.close()     \n",
    "\n",
    "    now_df = now_df.drop(['appId_y'], axis=1)\n",
    "   \n",
    "    return now_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#合并用户基本特征以及app使用相关特征，作为训练集和测试集\n",
    "df_train = mergeAppDataUpgrade(mergeBasicTables(age_train))\n",
    "df_test = mergeAppDataUpgrade(mergeBasicTables(age_test))\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"add_40_actived_classes_features.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二次特征工程——使用user_app_usage，计算每类app的使用时长\n",
    "\n",
    "df_train = pd.read_csv(\"add_40_actived_classes_features.csv\")\n",
    "#df_test = mergeAppDataUpgrade(mergeBasicTables(age_test))\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processUserAppUsageUpgrade(\"\", 'trainSet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdf = pd.read_csv('process_user_app_usage.csv')\n",
    "tempdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdf.drop([\"Unnamed: 0\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf.drop([\"Unnamed: 0\"], axis = 1).to_csv(\"process_user_app_usage_del_unname_column.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdf = pd.read_csv('process_user_app_usage_del_unname_column.csv')\n",
    "print(tempdf.head())\n",
    "print(tempdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"add_40_actived_classes_features.csv\")\n",
    "print(final_df.head())\n",
    "print(final_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, tempdf, how='left', on='uid').fillna(0)\n",
    "print(final_df.head())\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"2nd_feature_engineering_2010000_114.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"2nd_feature_engineering_2010000_114.csv\")\n",
    "\n",
    "print(df_train.head())\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectKBest, chi2, mutual_info_classif, f_classif\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_test = mergeAppDataUpgrade(mergeBasicTables(age_test))\n",
    "#df_test.to_csv(\"add_40_actived_classes_features_for_testSet.csv\",index=0)\n",
    "#final_test_df = pd.merge(df_test, tempdf, how='left', on='uid').fillna(0)\n",
    "#final_test_df.to_csv('2nd_feature_engineering_testSet_502500_113.csv',index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('2nd_feature_engineering_testSet_502500_113.csv')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"开始训练模型：\")\n",
    "param = {\n",
    "        'learning_rate': 0.15,\n",
    "        'lambda_l1': 1.05,\n",
    "        'lambda_l2': 0.01,\n",
    "        'max_depth': 25,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 7,\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_l-eaf': 50,\n",
    "        'max_bin': 230,\n",
    "        'feature_fraction': 0.8,\n",
    "        'metric': {'multi_error'}\n",
    "        }\n",
    "\n",
    "X = df_train.drop(['age_group','uid'], axis=1)\n",
    "y = df_train['age_group']\n",
    "uid = df_test['uid']\n",
    "test = df_test.drop('uid', axis=1)\n",
    "\n",
    "xx_score = []\n",
    "cv_pred = []\n",
    "skf = StratifiedKFold(n_splits=3, random_state=1030, shuffle=True)\n",
    "for index, (train_index, vali_index) in enumerate(skf.split(X, y)):\n",
    "    print(index)\n",
    "    x_train, y_train, x_vali, y_vali = np.array(X)[train_index], np.array(y)[train_index], np.array(X)[vali_index], np.array(y)[vali_index]\n",
    "    train = lgb.Dataset(x_train, y_train)\n",
    "    vali =lgb.Dataset(x_vali, y_vali)\n",
    "    print(\"training start...\")\n",
    "    model = lgb.train(param, train, num_boost_round=2000, valid_sets=[vali], early_stopping_rounds=50)\n",
    "    xx_pred = model.predict(x_vali,num_iteration=model.best_iteration)\n",
    "    xx_pred = [np.argmax(x) for x in xx_pred]\n",
    "    xx_score.append(f1_score(y_vali,xx_pred,average='weighted'))\n",
    "    y_test = model.predict(test,num_iteration=model.best_iteration)\n",
    "    y_test = [np.argmax(x) for x in y_test]\n",
    "    if index == 0:\n",
    "        cv_pred = np.array(y_test).reshape(-1, 1)\n",
    "    else:\n",
    "        cv_pred = np.hstack((cv_pred, np.array(y_test).reshape(-1, 1)))\n",
    "        \n",
    "submit = []\n",
    "for line in cv_pred:\n",
    "    submit.append(np.argmax(np.bincount(line)))\n",
    "df = pd.DataFrame({'id':uid.as_matrix(),'label':submit})\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
